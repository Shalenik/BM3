---
title: "Model Selection Across Multiple Replications"
author: "BFACT Package"
date: "2026-02-23"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Model Selection Across Multiple Replications}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    eval = TRUE,
    message = TRUE,
    warning = FALSE
)
```

# Model Selection Across Multiple Replications

This vignette demonstrates how to assess model selection performance (finding the true H) across multiple independent replications of the data. This is a key demonstration for the BFACT paper: showing that the method can reliably identify the true number of latent factors across different random realizations.

## Overview

We will:
1. Generate synthetic data with known true H value
2. Create 5 independent replications 
3. Fit BFACT with H=2 and H=3 to each replicate
4. Aggregate results across replications using `consolidate_results()`
5. Show summary statistics on model selection

## Step 1: Load Package and Data

```{r load-packages}
library(BFACT)
library(ggplot2)
library(dplyr)
```

## Step 2: Generate Multiple Replications

We'll generate 5 replications of synthetic data from a true H=2 model, using different random seeds:

```{r generate-replications}
# Generate synthetic data from real posterior
nc_file <- system.file("data", "NewYork_temperature_anomalies_JJA_all_models_1961-1990baseline.nc", package = "BFACT")
nc <- nc_open(nc_file)
temp_data <- ncvar_get(nc, "temperature")
years <- ncvar_get(nc, "year")
temp_avg <- apply(temp_data, c(3, 4, 5), mean, na.rm = TRUE)
climate_models <- list(z585c = temp_avg[, 3, ])
hadcrut_file <- system.file("data", "hadcrut5_annual.rds", package = "BFACT")
hadcrut5_annual <- readRDS(hadcrut_file)
nc_close(nc)

# Fit to real data to get a posterior draw
cat("Fitting BFACT to real data to generate posterior...\n")
fit_real <- BFACT(
    Y = climate_models$z585c,
    z = hadcrut5_annual,
    T = nrow(climate_models$z585c),
    T1 = 1,
    T2 = length(hadcrut5_annual),
    H = 2,
    iseed = 999,
    J = 6,
    nsim = 200
)

# Generate 5 replications from the posterior
n_reps <- 5
sims_list <- list()
for (rep in 1:n_reps) {
    cat(sprintf("Generating replicate %d/%d...\n", rep, n_reps))
    sim_rep <- simulate_from_posterior(
        fit_real,
        s = NULL, # Random sample from second half of chain
        seed = 1000 + rep
    )
    sims_list[[rep]] <- sim_rep
}

cat(sprintf("Generated %d replications with H_true = 2\n", n_reps))
```

## Step 3: Fit BFACT with Multiple H Values to Each Replicate

Now fit H=2 and H=3 to each replicate:

```{r fit-multiple-h}
H_values <- 2:3
fits_list <- list()

for (rep in 1:n_reps) {
    cat(sprintf("\n=== Replicate %d/%d ===\n", rep, n_reps))
    sim_rep <- sims_list[[rep]]
    fits_rep <- list()

    for (H in H_values) {
        cat(sprintf("  Fitting H=%d...\n", H))
        fit <- BFACT(
            Y = sim_rep$Y,
            z = sim_rep$z,
            T = sim_rep$T,
            T1 = sim_rep$T1,
            T2 = sim_rep$T2,
            H = H,
            iseed = 2000 + rep * 100 + H,
            J = 6,
            nsim = 200
        )
        fits_rep[[as.character(H)]] <- fit
    }
    fits_list[[rep]] <- fits_rep
}

cat("\nCompleted all fits!\n")
```

## Step 4: Consolidate Results Across Replications

Use the enhanced `consolidate_results()` to aggregate across replications:

```{r consolidate-replications}
results_multi <- consolidate_results(
    fits = fits_list,
    sim = sims_list,
    by_replicate = TRUE
)

# View the replicate comparison table
cat("\n=== Model Selection Summary Across Replications ===\n")
print(results_multi$replicate_comparison)
```

## Step 5: Identify the Elbow Point

Use the elbow method to identify the optimal H value where performance plateaus:

```{r elbow-identification}
# Extract H values and mean RMSE
H_vals <- results_multi$replicate_comparison$H
rmse_vals <- results_multi$replicate_comparison$mean_RMSE

# Find the elbow
elbow_H <- find_elbow(H_vals, rmse_vals, minimize = TRUE)

cat(sprintf("\nElbow point identified at H = %d\n", elbow_H))
cat(sprintf(
    "Mean RMSE at H=%d: %.4f\n", elbow_H,
    results_multi$replicate_comparison$mean_RMSE[
        results_multi$replicate_comparison$H == elbow_H
    ]
))
```

## Step 6: Visualize Model Selection Performance with Elbow

Plot RMSE by H across replications with elbow point marked:

```{r plot-model-selection}
# Detailed results by replicate
p_detail <- results_multi$replicate_results %>%
    ggplot(aes(x = factor(H), y = RMSE, fill = factor(replicate))) +
    geom_col(position = "dodge", alpha = 0.7) +
    geom_hline(yintercept = 0, linetype = "solid", color = "black", linewidth = 0.3) +
    theme_minimal() +
    labs(
        title = "Model Selection Across 5 Replications",
        subtitle = "Data generated from H_true = 2",
        x = "Fitted H",
        y = "RMSE",
        fill = "Replicate"
    ) +
    theme(
        legend.position = "right",
        plot.title = element_text(face = "bold", size = 14),
        plot.subtitle = element_text(size = 12, color = "gray50")
    )

print(p_detail)

# Summary with error bars and elbow point
p_summary <- results_multi$replicate_comparison %>%
    ggplot(aes(x = factor(H), y = mean_RMSE)) +
    geom_col(fill = "steelblue", alpha = 0.6, width = 0.4) +
    geom_errorbar(
        aes(ymin = mean_RMSE - sd_RMSE, ymax = mean_RMSE + sd_RMSE),
        width = 0.2, color = "steelblue", linewidth = 1
    ) +
    geom_vline(xintercept = elbow_H - 1.5, linetype = "dashed", color = "red", alpha = 0.7, linewidth = 1.2) +
    geom_vline(xintercept = 1.5, linetype = "dotted", color = "darkgreen", alpha = 0.5, linewidth = 1) +
    theme_minimal() +
    labs(
        title = "Average Model Performance with Elbow Detection",
        subtitle = sprintf("Red dashed = Elbow (H=%d); Green dotted = H_true", elbow_H),
        x = "Fitted H",
        y = "Mean RMSE"
    ) +
    theme(
        plot.title = element_text(face = "bold", size = 14),
        plot.subtitle = element_text(size = 12, color = "gray50")
    )

print(p_summary)
```

## Key Findings

From the replicate comparison table and elbow analysis, we can assess:

1. **Model Selection**: Does H=2 have lower mean RMSE than H=3?
2. **Consistency**: How much variation in RMSE across replications (sd_RMSE)?
3. **Range**: What is the min/max RMSE observed?
4. **Elbow Point**: At what H does RMSE improvement plateau? (identified by `find_elbow()`)

For a well-functioning method, we expect:
- H=2 (true H) to have mean_RMSE < H=3 across replications
- Relatively small sd_RMSE (low variance in selection across replications)
- Clear separation between true H and alternative H values
- Elbow point to occur at or near H_true, indicating where adding more factors stops helping

## Elbow Method for Automated Model Selection

The `find_elbow()` function uses perpendicular distance method to identify where the RMSE curve transitions from steep to flat. This provides an automated, data-driven approach to model selectionâ€”particularly useful when the optimal H is ambiguous from raw metrics alone.

## Comparison to Single Replication

Compare this to the single-replicate analysis from Vignette 02. With multiple replications, we can:
- Estimate the probability that the true H is selected
- Quantify selection uncertainty
- Show robustness of the method
- Use the elbow method to identify consistent optimal H across replications

This is the core demonstration for the BFACT paper's model selection claims.
